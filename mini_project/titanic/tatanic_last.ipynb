{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b99f1cb",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a38312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 12:33:00.159244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tensorflow.keras import models, layers, Sequential, initializers\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe5a7c",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17fddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./titanic/train.csv\")\n",
    "\n",
    "df_train.drop(columns=[\"PassengerId\", \"Cabin\"], inplace=True)\n",
    "\n",
    "df_train[\"Embarked\"].fillna(df_train[\"Embarked\"].unique()[0], inplace=True)\n",
    "\n",
    "df_train['Name'] = df_train['Name'].str.split(', ').str[1].str.split('. ').str[0]\n",
    "df_train['Master'] = (df_train['Name']=='Master')\n",
    "df_train=df_train.drop(columns='Name')\n",
    "df_train=df_train.drop(columns='Ticket')\n",
    "\n",
    "# age_new 컬럼 생성.\n",
    "df_train.loc[df_train.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_train.loc[(df_train.Age < 50) & (df_train.Age>=10), \"age_new\"] = \"young\"\n",
    "df_train.loc[df_train.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 인코딩\n",
    "og_columns = df_train.columns[(df_train.dtypes=='O')|(df_train.dtypes=='category')|(df_train.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_train_{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_train_{i}_encoder'].fit(df_train[i])\n",
    "    df_train[i] = globals()[f'df_train_{i}_encoder'].transform(df_train[i])\n",
    "    \n",
    "# 연령의 결측치 해결\n",
    "Age_md = df_train.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "df_train.loc[(df_train['Sex'] ==  0) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 0) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 0][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 1) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[1, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 2) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[2, 1][0]\n",
    "df_train.loc[(df_train['Sex'] == 1) & (df_train['Pclass'] == 3) & (df_train.Age.isna()), \"Age\"] = Age_md.loc[3, 1][0]\n",
    "\n",
    "df_train[\"family\"] = df_train.SibSp + df_train.Parch\n",
    "df_train.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "# X, Y , test, train 분리\n",
    "X = df_train.drop(columns='Survived')\n",
    "y = df_train['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb931a49",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7691cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./titanic/test.csv')\n",
    "\n",
    "df_test.drop(columns=[\"PassengerId\", \"Cabin\"], inplace=True)\n",
    "\n",
    "df_test['Name'] = df_test['Name'].str.split(', ').str[1].str.split('. ').str[0]\n",
    "df_test['Master']=(df_test['Name']=='Master')\n",
    "df_test=df_test.drop(columns='Name')\n",
    "df_test=df_test.drop(columns='Ticket')\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['mean'])\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'male') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'male'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 1) & (df_test.Age.isna()), 'Age'] = age_md.loc[1, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 2) & (df_test.Age.isna()), 'Age'] = age_md.loc[2, 'female'][0]\n",
    "df_test.loc[(df_test['Sex'] == 'female') & (df_test['Pclass'] == 3) & (df_test.Age.isna()), 'Age'] = age_md.loc[3, 'female'][0]\n",
    "df_test.Fare.fillna(df_test[\"Fare\"].mean(), inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "df_test[\"family\"] = df_test.SibSp + df_test.Parch\n",
    "df_test.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)\n",
    "\n",
    "og_columns = df_test.columns[(df_test.dtypes=='O')|(df_test.dtypes=='category')|(df_test.dtypes=='bool')]\n",
    "for i in og_columns : \n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856b12f",
   "metadata": {},
   "source": [
    "## Answer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21d4baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer = pd.read_csv(\"./titanic/answer_tit.csv\")\n",
    "df_answer = df_answer.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26312bf",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Deep Learning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c518e6f",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147582bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:23:13.257148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./tmp/checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m model_checkpoint_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     26\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_filepath, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2732\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m   func_cache_key, _ \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_cache_key(\n\u001b[1;32m   2729\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_input_signature, captures)\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2732\u001b[0m   \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2734\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2735\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments supplied to `defun`-generated functions must be hashable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2736\u001b[0m       ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_cache.py:175\u001b[0m, in \u001b[0;36mFunctionCacheKey.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 175\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures_signature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:207\u001b[0m, in \u001b[0;36mTuple.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:207\u001b[0m, in \u001b[0;36mTuple.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/default_types.py:601\u001b[0m, in \u001b[0;36mReference.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 601\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/type_spec.py:482\u001b[0m, in \u001b[0;36mTypeSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 482\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/type_spec.py:531\u001b[0m, in \u001b[0;36mTypeSpec.__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m# TODO(b/133606651): Decide whether to cache this value.\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__make_cmp_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/type_spec.py:549\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    543\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[1;32m    544\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[1;32m    545\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[1;32m    546\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    547\u001b[0m   ])\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 549\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    551\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/type_spec.py:549\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    543\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\n\u001b[1;32m    544\u001b[0m       \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(key),\n\u001b[1;32m    545\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(value[key])])\n\u001b[1;32m    546\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    547\u001b[0m   ])\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 549\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    551\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__make_cmp_key(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(8,))\n",
    "n = Dense(256, activation=\"elu\")(inputs)\n",
    "n = Dropout(0.5)(n)\n",
    "n = BatchNormalization()(n)\n",
    "n = Dense(128, activation=\"elu\")(n)\n",
    "n = Dropout(0.5)(n)\n",
    "n = BatchNormalization()(n)\n",
    "n = Dense(64, activation=\"elu\")(n)\n",
    "n = Dropout(0.5)(n)\n",
    "n = BatchNormalization()(n)\n",
    "n = Dense(32, activation=\"elu\")(n)\n",
    "n = Dropout(0.5)(n)\n",
    "n = BatchNormalization()(n)\n",
    "n = Dense(16, activation=\"elu\")(n)\n",
    "n = Dropout(0.5)(n)\n",
    "n = BatchNormalization()(n)\n",
    "n = Dense(1, activation=\"sigmoid\")(n)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=n)\n",
    "model.compile(loss=\"mse\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "checkpoint_filepath = './tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath, save_weights_only=True,\n",
    "    monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model.fit(X, y, epochs=300, verbose=0, validation_split=0.2, callbacks=[model_checkpoint_callback])\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(df_test, df_answer, verbose=2)\n",
    "\n",
    "print(f\"test loss : {test_loss}, test acc : {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432838b7",
   "metadata": {},
   "source": [
    "\n",
    "## Fit & Predict Model\n",
    "## Appraisal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=300, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83546f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(df_test, df_answer, verbose=2)\n",
    "\n",
    "print(f\"test loss : {test_loss}, test acc : {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49de80a",
   "metadata": {},
   "source": [
    "## HyperParameter in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    ip = Input(shape=(X.shape[1],))\n",
    "    n = BatchNormalization()(ip)\n",
    "    n = Dense(hp.Choice('units', [8, 16, 32, 64, 128, 256]),\n",
    "              activation='elu')(n)\n",
    "    n = Dropout(0.5)(n)\n",
    "    n = BatchNormalization()(n)\n",
    "    n = Dense(hp.Choice('units', [8, 16, 32, 64, 128, 256]),\n",
    "              activation='elu')(n)\n",
    "    n = BatchNormalization()(n)\n",
    "    n = Dense(hp.Choice('units', [8, 16, 32, 64, 128, 256]),\n",
    "              activation='elu')(n)\n",
    "    n = Dropout(0.5)(n)\n",
    "    n = BatchNormalization()(n)\n",
    "    n = Dense(hp.Choice('units', [8, 16, 32, 64, 128, 256]),\n",
    "              activation='elu')(n)\n",
    "    n = Dense(1, activation='sigmoid')(n)\n",
    "    model = Model(inputs=ip, outputs=n)\n",
    "    model.compile(loss='mse', optimizer=\"adam\", metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner4 = keras_tuner.RandomSearch(\n",
    "    build_model, objective='val_accuracy', max_trials=5, directory='./tuner4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc743c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner4.search(X, y, epochs=1000, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model3 = tuner4.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best is 3\n",
    "best_model3.evaluate(df_test, df_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c114c25",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Machine Learning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1513db",
   "metadata": {},
   "source": [
    "## VotingClassifier\n",
    "### RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6086e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918660287081339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=5, \n",
    "                                 criterion='entropy', max_features=None,)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, oob_score=True, max_depth=10, \n",
    "                              bootstrap=True, random_state=10, max_samples=1.0)\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=1000, \n",
    "                            max_samples=1.0, bootstrap=False, n_jobs=-1,\n",
    "                            bootstrap_features=True, max_features=0.5, oob_score=False)\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), \n",
    "                                            ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], \n",
    "                                voting='soft', n_jobs=-1)\n",
    "\n",
    "\n",
    "voting_model = VotingClassifier(estimators=[('RandomForestClassifier', rnd_clf), \n",
    "                                            ('BaggingClassifier', bag_clf),\n",
    "                                            ('ExtraTreesClassifier', et_clf)], \n",
    "                                voting='soft', n_jobs=-1)\n",
    "\n",
    "voting_model.fit(X, y)\n",
    "pred = voting_model.predict(df_test)\n",
    "accuracy_score(df_answer, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed6c1e",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7186fc9",
   "metadata": {},
   "source": [
    "### Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0daf6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "svm = SVC(random_state=0, probability=True)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "lr = LogisticRegression()\n",
    "hgb = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433c765",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c605faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "hgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c154a",
   "metadata": {},
   "source": [
    "### predict proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9295bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_proba = svm.predict_proba(X_train)[:, 1]\n",
    "rf_proba = rf.predict_proba(X_train)[:, 1]\n",
    "lr_proba = lr.predict_proba(X_train)[:, 1]\n",
    "hgb_proba = hgb.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1a977",
   "metadata": {},
   "source": [
    "### make meta dataframe\n",
    "> ###### 메타 데이터 프레임을 확인하여 모델의 성능을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76350a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_proba</th>\n",
       "      <th>rf_proba</th>\n",
       "      <th>lr_proba</th>\n",
       "      <th>hgb_proba</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310098</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.357313</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300966</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.108251</td>\n",
       "      <td>0.132029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301469</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.051128</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380672</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.924366</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.313118</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.302266</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>0.122317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.313652</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.240711</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.302451</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.081737</td>\n",
       "      <td>0.713913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.290220</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.068813</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     svm_proba  rf_proba  lr_proba  hgb_proba  y\n",
       "0     0.310098  0.020000  0.357313   0.035353  0\n",
       "1     0.300966  0.160000  0.108251   0.132029  0\n",
       "2     0.301469  0.010000  0.051128   0.012123  0\n",
       "3     0.301465  0.000000  0.071592   0.002521  0\n",
       "4     0.380672  0.997500  0.924366   0.987342  1\n",
       "..         ...       ...       ...        ... ..\n",
       "707   0.313118  0.910000  0.712041   0.878661  1\n",
       "708   0.302266  0.013048  0.138779   0.122317  0\n",
       "709   0.313652  0.080000  0.240711   0.032616  0\n",
       "710   0.302451  0.780000  0.081737   0.713913  1\n",
       "711   0.290220  0.010000  0.068813   0.006979  0\n",
       "\n",
       "[712 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([svm_proba, rf_proba, lr_proba, hgb_proba])\n",
    "meta_df = pd.DataFrame(new_data.T)\n",
    "meta_df.columns = ['svm_proba', 'rf_proba', 'lr_proba', 'hgb_proba']\n",
    "meta_df['y'] = y_train.values\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675a30e",
   "metadata": {},
   "source": [
    "###### 4개의 모델의 평균 값을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfa136bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.180691\n",
       "1      0.175311\n",
       "2      0.093680\n",
       "3      0.093895\n",
       "4      0.822470\n",
       "         ...   \n",
       "707    0.703455\n",
       "708    0.144102\n",
       "709    0.166745\n",
       "710    0.469525\n",
       "711    0.094003\n",
       "Length: 712, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de860d68",
   "metadata": {},
   "source": [
    "## stacking and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44bc6b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.01)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dt = DecisionTreeClassifier(ccp_alpha=0.01)\n",
    "meta_dt.fit(meta_df.drop('y', axis=1), meta_df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff02fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>lr_pred</th>\n",
       "      <th>lgbm_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310098</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.357313</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300966</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.108251</td>\n",
       "      <td>0.132029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301469</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.051128</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071592</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380672</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.924366</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.313118</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.302266</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>0.122317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.313652</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.240711</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.302451</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.081737</td>\n",
       "      <td>0.713913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.290220</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.068813</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     svm_pred   rf_pred   lr_pred  lgbm_pred  y\n",
       "0    0.310098  0.020000  0.357313   0.035353  0\n",
       "1    0.300966  0.160000  0.108251   0.132029  0\n",
       "2    0.301469  0.010000  0.051128   0.012123  0\n",
       "3    0.301465  0.000000  0.071592   0.002521  0\n",
       "4    0.380672  0.997500  0.924366   0.987342  1\n",
       "..        ...       ...       ...        ... ..\n",
       "707  0.313118  0.910000  0.712041   0.878661  1\n",
       "708  0.302266  0.013048  0.138779   0.122317  0\n",
       "709  0.313652  0.080000  0.240711   0.032616  0\n",
       "710  0.302451  0.780000  0.081737   0.713913  1\n",
       "711  0.290220  0.010000  0.068813   0.006979  0\n",
       "\n",
       "[712 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc8a79",
   "metadata": {},
   "source": [
    "### last fit model & evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77fb2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "lr_pred = lr.predict(X_test)\n",
    "hgb_pred = hgb.predict(X_test)\n",
    "\n",
    "new_data = np.array([svm_pred, rf_pred, lr_pred, hgb_pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d77978",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(new_data, df_answer)\n",
    "lgbm_pred = lgbm.predict(df_test)\n",
    "accuracy_score(df_test, lgbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d40afa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stk_clf = StackingClassifier([svm_pred, rf_pred, lr_pred, hgb_pred],\n",
    "    final_estimator=DecisionTreeClassifier(ccp_alpha=0.01),\n",
    "    cv=5,\n",
    "    stack_method='auto',\n",
    "    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b77ef4b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackingClassifier' object has no attribute 'final_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstk_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:607\u001b[0m, in \u001b[0;36mStackingClassifier.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params):\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m        Predicted targets.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 607\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_stacking.py:351\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_estimator_\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StackingClassifier' object has no attribute 'final_estimator_'"
     ]
    }
   ],
   "source": [
    "stk_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc872374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "602ec2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstk_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_answer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "stk_clf.predict(df_test, df_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d4340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
