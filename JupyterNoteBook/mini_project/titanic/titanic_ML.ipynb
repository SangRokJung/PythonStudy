{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "405eb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# 크롤링\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time, sys\n",
    "\n",
    "# 시각화 맵\n",
    "import folium\n",
    "\n",
    "# Label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# dtclf\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "finan_dtclf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "129c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터 전처리\n",
    "\n",
    "df_t = sns.load_dataset('titanic')\n",
    "df_t.drop(columns=['class', 'alive', 'embark_town', 'who', 'adult_male', 'alone'], inplace=True)\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "age_md = df_t.groupby(['pclass', 'sex']).age.agg(['median'])\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'male') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'male'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 1) & (df_t.age.isna()), \"age\"] = age_md.loc[1, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 2) & (df_t.age.isna()), \"age\"] = age_md.loc[2, 'female'][0]\n",
    "df_t.loc[(df_t['sex'] == 'female') & (df_t['pclass'] == 3) & (df_t.age.isna()), \"age\"] = age_md.loc[3, 'female'][0]\n",
    "\n",
    "# embarked 결측치 해결\n",
    "df_t.embarked.fillna(df_t.embarked.unique()[0], inplace=True)\n",
    "\n",
    "# 연령층 별 컬럼 생성.\n",
    "df_t.loc[df_t.age >= 50, \"age_new\"] = \"old\"\n",
    "df_t.loc[(df_t.age < 50) & (df_t.age>=10), \"age_new\"] = \"young\"\n",
    "df_t.loc[df_t.age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 불필요 컬럼 제거\n",
    "df_t.drop(columns=['deck', 'sibsp', 'parch', 'age', 'embarked'], inplace=True)\n",
    "\n",
    "# df_t.info()\n",
    "# sex, embarked, age_new 해결해야함\n",
    "\n",
    "# Labeling으로 문자형 데이터를 숫자형으로 변환\n",
    "for i in ['sex', 'survived', 'age_new']:\n",
    "    globals()[f'df_t{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_t{i}_encoder'].fit(df_t[i])\n",
    "    df_t[i] = globals()[f'df_t{i}_encoder'].transform(df_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6ca0c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 머신러닝 예측 학습\n",
    "\n",
    "# 머신러닝이 목적으로 할 데이터를 설정\n",
    "X = df_t.drop(columns='survived')\n",
    "y = df_t['survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "finan_dtclf_2 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# fit = 머신러닝의 학습의 의미\n",
    "finan_dtclf_2.fit(X, y)\n",
    "# 분석-decision tree classification\n",
    "\n",
    "# 시각화\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "export_graphviz(finan_dtclf_2, out_file='finance2.dot', \n",
    "                feature_names=X.columns,\n",
    "                class_names=['생존', '사망'],\n",
    "                max_depth=5,\n",
    "                filled=True,\n",
    "                leaves_parallel=False,\n",
    "                impurity=True,\n",
    "                node_ids=False,\n",
    "                proportion=False,)\n",
    "\n",
    "with open('./finance2.dot') as f :\n",
    "    finance2 = f.read()\n",
    "# graphviz.Source(finance2)\n",
    "\n",
    "# dot_graph의 source 저장\n",
    "# dot = graphviz.Source(finance2) \n",
    "# png로 저장\n",
    "# dot.render(filename='tree.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6e76fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 타이타닉 데이터 전처리 \n",
    "\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "# df_test.info()\n",
    "# Name, Sex, Ticket, Cabin, Embarked 해결 필요\n",
    "\n",
    "# 연령의 결측치 해결\n",
    "# fare 결측치 해결\n",
    "age_md = df_test.groupby(['Pclass', 'Sex']).Age.agg(['median'])\n",
    "fare_md = df_test.groupby(['Pclass', 'Sex']).Fare.agg(['median'])\n",
    "for i in ['male', 'female'] : \n",
    "    for y in range(1, 4) : \n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Age.isna()), 'Age'] = age_md.loc[{y}, '{i}'][0]\"\n",
    "        f\"df_test.loc[(df_test['Sex'] == '{i}') & (df_test['Pclass'] == {y}) & (df_test.Fare.isna()), 'Fare'] = fare_md.loc[{y}, '{i}'][0]\"\n",
    "        \n",
    "\n",
    "# 결측치가 너무 많은 데이터, 컬럼 삭제\n",
    "df_test.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# age_new 생성\n",
    "df_test.loc[df_test.Age >= 50, \"age_new\"] = \"old\"\n",
    "df_test.loc[(df_test.Age < 50) & (df_test.Age>=10), \"age_new\"] = \"young\"\n",
    "df_test.loc[df_test.Age < 10, \"age_new\"] = \"baby\"\n",
    "\n",
    "# 필요 없는 데이터 제거\n",
    "df_test.drop(columns=['Name', 'Ticket', 'PassengerId', \"SibSp\", \"Parch\", 'Age', 'Embarked'], inplace=True)\n",
    "\n",
    "\n",
    "# 컬럼 소문자로 변경 \n",
    "l1 = []\n",
    "for i in list(df_test.columns):\n",
    "    l1.append(i.lower())\n",
    "df_test.set_axis(l1, axis='columns', inplace=True)\n",
    "\n",
    "# Index(['pclass', 'sex', 'age', 'fare', 'embarked', 'predict survived'], dtype='object')\n",
    "# Labeling으로 문자형 데이터를 숫자형으로 변환\n",
    "for i in ['sex', 'age_new']:\n",
    "    globals()[f'df_test{i}_encoder'] = LabelEncoder()\n",
    "    globals()[f'df_test{i}_encoder'].fit(df_test[i])\n",
    "    df_test[i] = globals()[f'df_test{i}_encoder'].transform(df_test[i])\n",
    "\n",
    "df_test['fare'].fillna(df_test['fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "91a2c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 타이타닉 데이터 생존 여부 예측\n",
    "pred_result = finan_dtclf_2.predict(df_test)\n",
    "pred_result_2 =  df_tsurvived_encoder.inverse_transform(pred_result)\n",
    "df_test['survived'] = pred_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3f3cf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 70%, 테스트 데이터 30%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_t.drop('survived', axis=1)\n",
    "y = df_t.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12)\n",
    "\n",
    "# 직접구현\n",
    "# X_train = df_t.iloc[:round(891 * 0.7), 1:]\n",
    "# X_test = df_t.iloc[round(891 * 0.3), 1:]\n",
    "# y_train = df_t.iloc[:round(891 * 0.7), 0]\n",
    "# y_test = df_t.iloc[round(891 * 0.3), 0]\n",
    "\n",
    "# np.random.shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a917fe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79fca831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict이 필요한 이유 : 정답이 없는 경우가 있기 때문.\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c11a6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 학습 실행\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 폴드 세트를 5개인 KFold 객체를 생성, 폴드 수 만큼 예측 결과를 저장을 위한 리스트 객체 생성.\n",
    "def exe_kfold(clf, folds=5) : \n",
    "    \n",
    "    kFold = KFold(n_splits=folds)\n",
    "    scores=[]\n",
    "    \n",
    "    # KFold 교차 검증 수행\n",
    "    for i, (train_idx, val_idx) in enumerate(kFold.split(X_train)) :\n",
    "        # X_train 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train_k = X_train.iloc[train_idx]\n",
    "        y_train_k = y_train.iloc[train_idx]\n",
    "        X_val_k = X_train.iloc[val_idx]\n",
    "        y_val_k = y_train.iloc[val_idx]    \n",
    "        \n",
    "        # Classfier 학습, 예측, 정확도 계산\n",
    "        dt_clf.fit(X_train_k, y_train_k)\n",
    "        scores.append(dt_clf.score(X_val_k, y_val_k))\n",
    "    \n",
    "    # 5개 fold에서 평균 정확도 계산\n",
    "    print(f\"{clf} 개별 학습 결과 : \", scores)\n",
    "    print(f\"{clf} 평균 학습 결과 : %.2f\" %np.mean(scores))\n",
    "\n",
    "# DecisionTreeClassifier() 개별 학습 결과 :  [0.7577639751552795, 0.79375, 0.9, 0.8625, 0.84375]\n",
    "# DecisionTreeClassifier() 평균 학습 결과 : 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e4c2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7075d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold 학습 실행\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def exe_skfold(clf, folds=5) : \n",
    "    \n",
    "    skFold = StratifiedKFold(n_splits=folds)\n",
    "    scores=[]\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(skFold.split(X_train, y_train)) :\n",
    "        X_train_k = X_train.iloc[train_idx]\n",
    "        y_train_k = y_train.iloc[train_idx]\n",
    "        X_val_k = X_train.iloc[val_idx]\n",
    "        y_val_k = y_train.iloc[val_idx]    \n",
    "\n",
    "        dt_clf.fit(X_train_k, y_train_k)\n",
    "        scores.append(dt_clf.score(X_val_k, y_val_k))\n",
    "    print(f\"{clf} 개별 학습 결과 : \", scores)\n",
    "    print(f\"{clf} 평균 학습 결과 : %.2f\" %np.mean(scores))\n",
    "    \n",
    "# DecisionTreeClassifier() 개별 학습 결과 :  [0.7577639751552795, 0.7875, 0.875, 0.84375, 0.85625]\n",
    "# DecisionTreeClassifier() 평균 학습 결과 : 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74943672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99\n",
      "1    62\n",
      "Name: survived, dtype: int64\n",
      "0    99\n",
      "1    61\n",
      "Name: survived, dtype: int64\n",
      "0    99\n",
      "1    61\n",
      "Name: survived, dtype: int64\n",
      "0    99\n",
      "1    61\n",
      "Name: survived, dtype: int64\n",
      "0    98\n",
      "1    62\n",
      "Name: survived, dtype: int64\n",
      "0    95\n",
      "1    66\n",
      "Name: survived, dtype: int64\n",
      "0    100\n",
      "1     60\n",
      "Name: survived, dtype: int64\n",
      "0    106\n",
      "1     54\n",
      "Name: survived, dtype: int64\n",
      "0    100\n",
      "1     60\n",
      "Name: survived, dtype: int64\n",
      "0    93\n",
      "1    67\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# kFold, StratifiedKFold 성능 비교\n",
    "skFold = StratifiedKFold(n_splits=5)\n",
    "kFold = KFold(n_splits=5)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(skFold.split(X_train, y_train)):\n",
    "        test = y_train.iloc[val_idx]\n",
    "        print(test.value_counts())\n",
    "        \n",
    "# 0    99\n",
    "# 1    62\n",
    "# Name: survived, dtype: int64\n",
    "# 0    99\n",
    "# 1    61\n",
    "# Name: survived, dtype: int64\n",
    "# 0    99\n",
    "# 1    61\n",
    "# Name: survived, dtype: int64\n",
    "# 0    99\n",
    "# 1    61\n",
    "# Name: survived, dtype: int64\n",
    "# 0    98\n",
    "# 1    62\n",
    "# Name: survived, dtype: int64\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kFold.split(X_train, y_train)):\n",
    "        test = y_train.iloc[val_idx]\n",
    "        print(test.value_counts())\n",
    "        \n",
    "# Name: survived, dtype: int64\n",
    "# 0    95\n",
    "# 1    66\n",
    "# Name: survived, dtype: int64\n",
    "# 0    100\n",
    "# 1     60\n",
    "# Name: survived, dtype: int64\n",
    "# 0    106\n",
    "# 1     54\n",
    "# Name: survived, dtype: int64\n",
    "# 0    100\n",
    "# 1     60\n",
    "# Name: survived, dtype: int64\n",
    "# 0    93\n",
    "# 1    67\n",
    "# Name: survived, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65f308d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253027950310559"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(estimator=dt_clf, X=X_train, y=y_train, cv=5)\n",
    "# array([0.75776398, 0.7875    , 0.875     , 0.84375   , 0.85625   ])\n",
    "\n",
    "# n_jobs : cpu 코어당 병렬로 작업을 가능하게 하는 옵션, 코어당 2개이상도 작업이 가능하다.\n",
    "# cv : 폴드 개수, 몇개를 분활 할지 설정, 5개면 1/5로 분할\n",
    "\n",
    "np.mean(cross_val_score(estimator=dt_clf, X=X_train, y=y_train, cv=5))\n",
    "# 0.8253027950310559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d7a40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loocv 평균 학습 결과 : 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores= []\n",
    "\n",
    "# 행의 갯수만큼, 행을 학습 시킴.\n",
    "# columns length * columns length\n",
    "loocv = LeaveOneOut()\n",
    "for train_idx, val_idx  in loocv.split(X_train) :\n",
    "    X_train_loo = X_train.iloc[train_idx] # 학습지의 문제\n",
    "    X_val_loo = X_train.iloc[val_idx] # 시험지의 문제\n",
    "    y_train_loo = y_train.iloc[train_idx] # 학습지의 정답\n",
    "    y_val_loo = y_train.iloc[val_idx] # 시험지의 정답\n",
    "     \n",
    "    dt_clf.fit(X_train_loo, y_train_loo) # 학습지의 문제와 정답을 보면서 학습\n",
    "    scores.append(dt_clf.score(X_val_loo, y_val_loo)) # 시험지의 문제로 시험을 치루고 정답값과 비교\n",
    "    \n",
    "print(\"loocv 평균 학습 결과 : %.2f\" %np.mean(scores))\n",
    "# loocv 평균 학습 결과 : 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2d999b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpocv 평균 학습 결과 : 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "scores= []\n",
    "\n",
    "\n",
    "# 행의 갯수만큼, 행을 학습 시킴.\n",
    "# columns length * columns length\n",
    "lpocv = LeavePOut(2)\n",
    "\n",
    "for i, (train_idx, val_idx)  in enumerate(lpocv.split(X_train)) :\n",
    "    if i == 500 :\n",
    "        break\n",
    "    X_train_lpo = X_train.iloc[train_idx] # 학습지의 문제\n",
    "    X_val_lpo = X_train.iloc[val_idx] # 시험지의 문제\n",
    "    y_train_lpo = y_train.iloc[train_idx] # 학습지의 정답\n",
    "    y_val_lpo = y_train.iloc[val_idx] # 시험지의 정답\n",
    "    \n",
    "    dt_clf.fit(X_train_lpo, y_train_lpo) # 학습지의 문제와 정답을 보면서 학습\n",
    "    scores.append(dt_clf.score(X_val_lpo, y_val_lpo)) # 시험지의 문제로 시험을 치루고 정답값과 비교\n",
    "    \n",
    "print(\"lpocv 평균 학습 결과 : %.2f\" %np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e96cb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111111111111111"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f78b784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "720 : 81\n",
      "sft 평균 학습 결과 : 0.88\n"
     ]
    }
   ],
   "source": [
    "# ShuffleSplit(REPEATED RANDOM SUB SAMPLING VALIDATION) 검증 \n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(test_size=0.2, n_splits=5, random_state=14)\n",
    "\n",
    "for i, (train_idx, val_idx)  in enumerate(ss.split(X_train)) :\n",
    "    X_train_ss = X_train.iloc[train_idx] # 학습지의 문제\n",
    "    X_val_ss = X_train.iloc[val_idx] # 시험지의 문제\n",
    "    y_train_ss = y_train.iloc[train_idx] # 학습지의 정답\n",
    "    y_val_ss = y_train.iloc[val_idx] # 시험지의 정답\n",
    "    \n",
    "    dt_clf.fit(X_train_ss, y_train_ss) # 학습지의 문제와 정답을 보면서 학습\n",
    "    scores.append(dt_clf.score(X_val_ss, y_val_ss)) # 시험지의 문제로 시험을 치루고 정답값과 비교\n",
    "    \n",
    "    print(len(train_idx), \":\" , len(val_idx))\n",
    "    \n",
    "print(\"sft 평균 학습 결과 : %.2f\" %np.mean(scores))\n",
    "\n",
    "# 720 : 81\n",
    "# sft 평균 학습 결과 : 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bd8d7aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] \n",
      " [2]\n",
      "[0 1 2] \n",
      " [3]\n",
      "[0 1 2 3] \n",
      " [4]\n",
      "[0 1 2 3 4] \n",
      " [5]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], \n",
    "              [3, 4], \n",
    "             [1, 2], \n",
    "             [3, 4],\n",
    "             [1, 2], \n",
    "             [3, 4]])\n",
    "# y = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "ts = TimeSeriesSplit(n_splits=4)\n",
    "for trn, val in ts.split(X) :\n",
    "    print(trn,\"\\n\",val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bc0346f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=6)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_clf.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f5c525d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'max_dept' : [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, None],\n",
    "#          'min_dept' : [range(1, 8)]}\n",
    "\n",
    "params = {\"criterion\":['gini', 'entropy'],\n",
    "        \"splitter\":['best', 'random'],\n",
    "        \"max_depth\":range(3, 17),\n",
    "        \"min_samples_split\":range(2, 20),\n",
    "        \"min_samples_leaf\":range(1, 20),\n",
    "        \"max_features\" : [None, \"auto\", \"sqrt\", \"log2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "847e9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_dtclf = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', \n",
    "                         n_jobs=-1, cv=5, verbose=1)\n",
    "\n",
    "# verbose : 학습의과정 옵션\n",
    "# n_jobs : 코어를 얼마나 사용할 것인가, -1을 하게되면 최대의 코어 사용\n",
    "# cv(cross valueation) : 몇개를 자를것인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "24bcf1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 76608 candidates, totalling 383040 fits\n",
      "CPU times: user 2min 31s, sys: 4.52 s, total: 2min 36s\n",
      "Wall time: 4min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(max_depth=6), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(3, 17),\n",
       "                         'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': range(1, 20),\n",
       "                         'min_samples_split': range(2, 20),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_dtclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0c85b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = gs_dtclf.best_params_\n",
    "# {'criterion': 'gini',\n",
    "#  'max_depth': 15,\n",
    "#  'max_features': 'log2',\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'min_samples_split': 8,\n",
    "#  'splitter': 'random'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "cfab8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf_best = DecisionTreeClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3c84ea52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452096273291925"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtclf.best_score_\n",
    "# 0.8402639751552796\n",
    "# test데이터가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7da1b088",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(3) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [349]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdt_clf_best\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    163\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 165\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    169\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m     check_X_params, check_y_params \u001b[38;5;241m=\u001b[39m validate_separately\n\u001b[1;32m    578\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m--> 579\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:803\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    809\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:269\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[1;32m    271\u001b[0m         )\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(3) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "dt_clf_best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c8946c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = dt_clf_best.predict(df_test)\n",
    "pred_result_2 =  df_tsurvived_encoder.inverse_transform(pred_result)\n",
    "df_test['survived'] = pred_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "f1300edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장해서 캐글에 올리기.\n",
    "tit = pd.read_csv('test.csv')\n",
    "tit.drop(list(tit.columns)[1:], axis = 1, inplace=True)\n",
    "tit['Survived'] = df_test['survived']\n",
    "tit.set_index('PassengerId', inplace=True)\n",
    "tit.to_csv('tit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c5f9f44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=17)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finan_dtclf_2 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# fit = 머신러닝의 학습의 의미\n",
    "finan_dtclf_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "0e30eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = finan_dtclf_2.predict(df_test)\n",
    "pred_result_2 =  df_tsurvived_encoder.inverse_transform(pred_result)\n",
    "df_test['survived'] = pred_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "874131a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "02a65c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_t.drop(columns='survived')\n",
    "y = df_t['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7547f345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>age_new</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sex      fare  age_new  survived\n",
       "0         3    1    7.8292        2         0\n",
       "1         3    0    7.0000        2         1\n",
       "2         2    1    9.6875        1         0\n",
       "3         3    1    8.6625        2         0\n",
       "4         3    0   12.2875        2         1\n",
       "..      ...  ...       ...      ...       ...\n",
       "413       3    1    8.0500        3         0\n",
       "414       1    0  108.9000        2         1\n",
       "415       3    1    7.2500        2         0\n",
       "416       3    1    8.0500        3         0\n",
       "417       3    1   22.3583        3         0\n",
       "\n",
       "[418 rows x 5 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(‘ignore’)\n",
    "df = sns.load_dataset(‘titanic’)\n",
    "df.drop([‘class’, ‘alive’, ‘embark_town’, ‘who’, ‘adult_male’, ‘alone’], axis=1, inplace=True)\n",
    "df[‘family’] = df.sibsp + df.parch\n",
    "df.drop([‘sibsp’, ‘parch’], axis=1, inplace=True)\n",
    "df1 = df.copy()\n",
    "df1.embarked.fillna(‘S’, inplace=True)\n",
    "m1_med = df1.loc[(df1.sex == ‘male’) & (df1.pclass == 1), ‘age’].median()\n",
    "m2_med = df1.loc[(df1.sex == ‘male’) & (df1.pclass == 2), ‘age’].median()\n",
    "m3_med = df1.loc[(df1.sex == ‘male’) & (df1.pclass == 3), ‘age’].median()\n",
    "f1_med = df1.loc[(df1.sex == ‘female’) & (df1.pclass == 1), ‘age’].median()\n",
    "f2_med = df1.loc[(df1.sex == ‘female’) & (df1.pclass == 2), ‘age’].median()\n",
    "f3_med = df1.loc[(df1.sex == ‘female’) & (df1.pclass == 3), ‘age’].median()\n",
    "df1.loc[(df1.sex == ‘male’)&(df1.pclass == 1), ‘age’].fillna(29, inplace=True)\n",
    "df1.loc[(df1.sex == ‘male’)  &(df1.pclass == 1)&(df1.age.isna()), ‘age’] = m1_med\n",
    "df1.loc[(df1.sex == ‘male’)  &(df1.pclass == 2)&(df1.age.isna()), ‘age’] = m2_med\n",
    "df1.loc[(df1.sex == ‘male’)  &(df1.pclass == 3)&(df1.age.isna()), ‘age’] = m3_med\n",
    "df1.loc[(df1.sex == ‘female’)&(df1.pclass == 1)&(df1.age.isna()), ‘age’] = f1_med\n",
    "df1.loc[(df1.sex == ‘female’)&(df1.pclass == 2)&(df1.age.isna()), ‘age’] = f2_med\n",
    "df1.loc[(df1.sex == ‘female’)&(df1.pclass == 3)&(df1.age.isna()), ‘age’] = f3_med\n",
    "df1.drop(‘deck’, axis=1, inplace=True)\n",
    "df1.age_new = 0\n",
    "# 노인의 생존율 (50세 이상) 유아의 생존율 (10세 미만)\n",
    "df1.loc[df1.age >= 50, ‘age_new’] = ‘old’\n",
    "df1.loc[(df1.age < 50) & (df1.age>=10), ‘age_new’] = ‘young’\n",
    "df1.loc[df1.age < 10, ‘age_new’] = ‘baby’\n",
    "for i in [‘sex’, ‘embarked’, ‘age_new’]:\n",
    "    globals()[f’df1_{i}_encoder’] = LabelEncoder()\n",
    "    globals()[f’df1_{i}_encoder’].fit(df1[i])\n",
    "    df1[i] = globals()[f’df1_{i}_encoder’].transform(df1[i])\n",
    "df1_sex_encoder = LabelEncoder()\n",
    "df1_embarked_encoder = LabelEncoder()\n",
    "df1_agenew_encoder = LabelEncoder()\n",
    "df1_sex_encoder.fit(df1[‘sex’])\n",
    "df1_embarked_encoder.fit(df1[‘embarked’])\n",
    "df1_agenew_encoder.fit(df1[‘age_new’])\n",
    "df1[‘sex’] = df1_sex_encoder.transform(df1[‘sex’])\n",
    "df1[‘embarked’] = df1_embarked_encoder.transform(df1[‘embarked’])\n",
    "df1[‘age_new’] = df1_agenew_encoder.transform(df1[‘age_new’])\n",
    "X = df1.drop(‘survived’, axis=1)\n",
    "y = df1.survived\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Tuning Multiple Hyperparameters\n",
    "# read in hyperopt values\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "# redefine the function usng a wider range of hyperparameters\n",
    "def objective(search_space):\n",
    "    model = DecisionTreeClassifier(**search_space)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return {‘loss’: -accuracy, ‘status’: STATUS_OK}\n",
    "# new search space\n",
    "search_space={‘max_depth’:hp.choice(‘max_depth’, range(3, 17)),\n",
    "              ‘min_samples_split’:hp.uniform(‘min_samples_split’, 0, 1),\n",
    "              ‘min_samples_leaf’:hp.choice(‘min_samples_leaf’, range(1, 30)),\n",
    "              ‘criterion’:hp.choice(‘criterion’, [‘gini’,‘entropy’]),\n",
    "              ‘max_features’:hp.choice(‘max_features’, [None, ‘sqrt’, ‘log2’])}\n",
    "# set the hyperparam tuning algorithm\n",
    "algorithm=tpe.suggest\n",
    "# implement Hyperopt\n",
    "best_params = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=algorithm,\n",
    "    max_evals=100)\n",
    "space_eval(search_space, best_params)\n",
    "5:48\n",
    "space_eval(search_space, best_params)\n",
    "5:48\n",
    "new_dtclf = DecisionTreeClassifier(**space_eval(search_space, best_params))\n",
    "new_dtclf.fit(X_train, y_train)\n",
    "5:48\n",
    "new_dtclf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
