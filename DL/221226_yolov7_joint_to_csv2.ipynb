{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56edd76b",
   "metadata": {},
   "source": [
    "# Installing YOLOv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddccee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "# ! git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3ba98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/werther\n"
     ]
    }
   ],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bd06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/werther/yolov7\n",
      "4124287451827527828img_5023-1_keypoint.mp4\r\n",
      "4124287451827527828img_5023-2_keypoint.mp4\r\n",
      "4124287451827527828img_5023-3_keypoint.mp4\r\n",
      "4124287451827527828img_5023-4_keypoint.mp4\r\n",
      "4124287451827527828img_5023-5_keypoint.mp4\r\n",
      "4124287451827527828img_5023-6_keypoint.mp4\r\n",
      "4124287451827527828img_5023-7_keypoint.mp4\r\n",
      "4124287451827527828img_5023-8_keypoint.mp4\r\n",
      "4124287451827527828img_5023-9_keypoint.mp4\r\n",
      "4124287451827527828img_5023_keypoint.mp4\r\n",
      "LICENSE.md\r\n",
      "README.md\r\n",
      "\u001b[34mcfg\u001b[m\u001b[m\r\n",
      "dasol_pose_side_v_keypoint.mp4\r\n",
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "\u001b[34mdeploy\u001b[m\u001b[m\r\n",
      "detect.py\r\n",
      "export.py\r\n",
      "\u001b[34mfigure\u001b[m\u001b[m\r\n",
      "hubconf.py\r\n",
      "\u001b[34minference\u001b[m\u001b[m\r\n",
      "\u001b[34mmodels\u001b[m\u001b[m\r\n",
      "\u001b[34mpaper\u001b[m\u001b[m\r\n",
      "requirements.txt\r\n",
      "\u001b[34mscripts\u001b[m\u001b[m\r\n",
      "test.py\r\n",
      "\u001b[34mtools\u001b[m\u001b[m\r\n",
      "train.py\r\n",
      "train_aux.py\r\n",
      "\u001b[34mutils\u001b[m\u001b[m\r\n",
      "yolov7-w6-pose.pt\r\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd51959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  153M  100  153M    0     0  19.5M      0  0:00:07  0:00:07 --:--:-- 22.1M 0  0:00:13  0:00:01  0:00:12 18.7M0:00:05  0:00:03 19.8M\n"
     ]
    }
   ],
   "source": [
    "! curl -L https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt -o yolov7-w6-pose.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c82805",
   "metadata": {},
   "source": [
    "# Loading the YOLOv7 Pose Estimation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69030c",
   "metadata": {},
   "source": [
    "torch and torchvision are straightforward enough - YOLOv7 is implemented with PyTorch. The utils.datasets, utils.general and utils.plots modules come from the YOLOv7 project, and provide us with methods that help with preprocessing and preparing input for the model to run inference on. Amongst those are letterbox() to pad the image, non_max_supression_keypoint() to run the Non-Max Supression algorithm on the initial output of the model and to produce a clean output for our interpretation, as well as the output_to_keypoint() and plot_skeleton_kpts() methods to actually add keypoints to a given image, once they're predicted.\n",
    "\n",
    "We can load the model from the weight file with torch.load(). Let's create a function to check if a GPU is available, load the model, put it in inference mode and move it to the GPU if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd25a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !install python3-tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8003200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa84e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8adda3",
   "metadata": {},
   "source": [
    "We can load the model from the weight file with torch.load(). Let's create a function to check if a GPU is available, load the model, put it in inference mode and move it to the GPU if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2401782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load('/Users/werther/yolov7/yolov7-w6-pose.pt', map_location=device)['model']\n",
    "    # Put in inference mode\n",
    "    model.float().eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # half() turns predictions into float16 tensors\n",
    "        # which significantly lowers inference time\n",
    "        model.half().to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf509f51",
   "metadata": {},
   "source": [
    "With the model loaded, let's create a run_inference() method that accepts a string pointing to a file on our system. The method will read the image using OpenCV (cv2), pad it with letterbox(), apply transforms to it, and turn it into a batch (the model is trained on and expects batches, as usual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093ba57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(url):\n",
    "    image = cv2.imread(url) # shape: (480, 640, 3)\n",
    "    # Resize and pad image\n",
    "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (768, 960, 3)\n",
    "    # Apply transforms\n",
    "    image = transforms.ToTensor()(image) # torch.Size([3, 768, 960])\n",
    "    # Turn image into batch\n",
    "    image = image.unsqueeze(0) # torch.Size([1, 3, 768, 960])\n",
    "    output, _ = model(image) # torch.Size([1, 45900, 57])\n",
    "    return output, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea45544",
   "metadata": {},
   "source": [
    "Here, we've returned the transformed image (because we'll want to extract the original and plot on it) and the outputs of the model. These outputs contain 45900 keypoint predictions, most of which overlap. We'll want to apply Non-Max Supression to these raw predictions, just as with Object Detection predictions (where many bounding boxes are predicted and then they're \"collapsed\" given some confidence and IoU threshold). After supression, we can plot each keypoint on the original image and display it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcbfaef",
   "metadata": {},
   "source": [
    "Now, for some input image, such as karate.jpg in the main working directory, we can run inference, perform Non-Max Supression and plot the results with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bda54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_coordinate = {}\n",
    "reps_num = 1 # 랩스 넘버링(초기값 1)\n",
    "frame_num = 1 # 이미지(=프레임) 넘버링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에 스켈레톤을 그리는 함수2 => 리스트에 저장\n",
    "def plot_skeleton_kpts(im, kpts, steps, orig_shape=None):\n",
    "    # (추가) 좌표값들을 저장할 리스트, 데이터프레임으로 만들 딕셔너리\n",
    "    lst_coordinate = []\n",
    "    \n",
    "    #Plot the skeleton and keypointsfor coco datatset\n",
    "    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n",
    "                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n",
    "                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n",
    "                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n",
    "                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n",
    "                        [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0],\n",
    "                        [255, 255, 255]])\n",
    "\n",
    "    skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],\n",
    "                [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],\n",
    "                [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]\n",
    "\n",
    "    pose_limb_color = palette[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]\n",
    "    pose_kpt_color = palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]\n",
    "    radius = 5\n",
    "    num_kpts = len(kpts) // steps\n",
    "\n",
    "    for kid in range(num_kpts):\n",
    "        r, g, b = pose_kpt_color[kid]\n",
    "        x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
    "        if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
    "            if steps == 3:\n",
    "                conf = kpts[steps * kid + 2]\n",
    "                if conf < 0.5:\n",
    "                    continue\n",
    "#             cv2.circle(im, (int(x_coord), int(y_coord)), radius, (int(r), int(g), int(b)), -1)\n",
    "            \n",
    "#             # (추가) 각 포인트마다 좌표를 이미지에 출력한다.\n",
    "#             font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#             text = f'({int(x_coord)}, {int(y_coord)})'\n",
    "#             cv2.putText(im, text, (int(x_coord), int(y_coord)), font, 0.5, (int(r), int(g), int(b)), 2)\n",
    "            \n",
    "            # (추가) 포인트 좌표를 리스트에 추가, \n",
    "            lst_coordinate.append(int(x_coord))\n",
    "            lst_coordinate.append(int(y_coord))\n",
    "            \n",
    "    \n",
    "    # (추가) 포인트의 개수가 17개보다 적을 경우(얼굴이 잘려 있는 영상의 경우, 포인트의 개수가 적다) : 결측치로 채우기\n",
    "    if len(lst_coordinate) < 34:\n",
    "        lst_nan = []\n",
    "        for i in range(34 - len(lst_coordinate)):\n",
    "            lst_nan.append(np.nan)\n",
    "        lst_coordinate = lst_nan + lst_coordinate\n",
    "        \n",
    "    # (추가) 좌표 리스트를 딕셔너리에 추가\n",
    "    dict_coordinate[f'img_{reps_num}_{frame_num}'] = lst_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0ad2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def visualize_output(output):\n",
    "    output = non_max_suppression_kpt(output,\n",
    "                                     0.25, # Confidence Threshold\n",
    "                                     0.65, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "    lst_coordinate = []\n",
    "    for idx in range(output.shape[0]):\n",
    "        steps = 3\n",
    "        kpts = output[idx, 7:].T\n",
    "        num_kpts = len(kpts) // steps\n",
    "        for kid in range(num_kpts):\n",
    "            x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
    "            if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
    "                if steps == 3:\n",
    "                    conf = kpts[steps * kid + 2]\n",
    "                    if conf < 0.5:\n",
    "                        continue\n",
    "                # (추가) 포인트 좌표를 리스트에 추가,\n",
    "                lst_coordinate.append(int(x_coord))\n",
    "                lst_coordinate.append(int(y_coord))\n",
    "        # (추가) 포인트의 개수가 17개보다 적을 경우(얼굴이 잘려 있는 영상의 경우, 포인트의 개수가 적다) : 결측치로 채우기\n",
    "        if len(lst_coordinate) < 34:\n",
    "            lst_nan = []\n",
    "            for i in range(34 - len(lst_coordinate)):\n",
    "                lst_nan.append(np.nan)\n",
    "            lst_coordinate = lst_nan + lst_coordinate\n",
    "    return lst_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c194590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def visualize_output(output):\n",
    "    output = non_max_suppression_kpt(output,\n",
    "                                     0.25, # Confidence Threshold\n",
    "                                     0.65, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "    lst_coordinate = []\n",
    "    for idx in range(output.shape[0]):\n",
    "        steps = 3\n",
    "        kpts = output[idx, 7:].T\n",
    "        num_kpts = len(kpts) // steps\n",
    "        for kid in range(num_kpts):\n",
    "            x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
    "            if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
    "                if steps == 3:\n",
    "                    conf = kpts[steps * kid + 2]\n",
    "                    if conf < 0.5:\n",
    "                        continue\n",
    "                # (추가) 포인트 좌표를 리스트에 추가,\n",
    "                lst_coordinate.append(int(x_coord))\n",
    "                lst_coordinate.append(int(y_coord))\n",
    "        # (추가) 포인트의 개수가 17개보다 적을 경우(얼굴이 잘려 있는 영상의 경우, 포인트의 개수가 적다) : 결측치로 채우기\n",
    "        if len(lst_coordinate) < 34:\n",
    "            lst_nan = []\n",
    "            for i in range(34 - len(lst_coordinate)):\n",
    "                lst_nan.append(np.nan)\n",
    "            lst_coordinate = lst_nan + lst_coordinate\n",
    "        # (추가) 좌표 리스트를 딕셔너리에 추가\n",
    "        dict_coordinate[f'img_{reps_num}_{frame_num}'] = lst_coordinate\n",
    "        print(f'{reps_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e3f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(output, image):\n",
    "    output = non_max_suppression_kpt(output, \n",
    "                                     0.25, # Confidence Threshold\n",
    "                                     0.65, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "    lst_coordinate = []\n",
    "    for idx in range(output.shape[0]):\n",
    "        steps = 3\n",
    "        kpts = output[idx, 7:].T\n",
    "        num_kpts = len(kpts) // steps\n",
    "\n",
    "        for kid in range(num_kpts):\n",
    "            x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
    "            if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
    "                if steps == 3:\n",
    "                    conf = kpts[steps * kid + 2]\n",
    "                    if conf < 0.5:\n",
    "                        continue\n",
    "\n",
    "                # (추가) 포인트 좌표를 리스트에 추가, \n",
    "                lst_coordinate.append(int(x_coord))\n",
    "                lst_coordinate.append(int(y_coord))\n",
    "\n",
    "        # (추가) 포인트의 개수가 17개보다 적을 경우(얼굴이 잘려 있는 영상의 경우, 포인트의 개수가 적다) : 결측치로 채우기\n",
    "        if len(lst_coordinate) < 34:\n",
    "            lst_nan = []\n",
    "            for i in range(34 - len(lst_coordinate)):\n",
    "                lst_nan.append(np.nan)\n",
    "            lst_coordinate = lst_nan + lst_coordinate\n",
    "\n",
    "        # (추가) 좌표 리스트를 딕셔너리에 추가\n",
    "        dict_coordinate[f'img_{reps_num}_{frame_num}'] = lst_coordinate\n",
    "        print(f'{reps_num}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "#     cv2.imshow('lena color', nimg)   \n",
    "\n",
    "# 이미지 출력문\n",
    "#     plt.figure(figsize=(12, 12))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(nimg)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17eeeef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# path = f'C:/Users/Playdata/Desktop/playdata/python/project/dataset/eunseong_squat_img/no{reps_num}'\n",
    "# os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394db2e7",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 이미지의 joint points -> csv 과정\n",
    "\n",
    "1. n번 랩스 이미지들의 포인트 좌표 추출하기\n",
    "2. 추출한 좌표는 딕셔너리 dict_coordinate에 저장됨\n",
    "3. dict_coordinate를 데이터프레임 df으로 만든다\n",
    "4. df.to_csv()로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd9c2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 이미지에서 포인트 좌표와 포인트 출력 => 다 나올 경우 총 17개의 포인트가 나온다.\n",
    "output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_1.jpg') # Bryan Reyes on Unsplash\n",
    "\n",
    "visualize_output(output, image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd1198",
   "metadata": {},
   "source": [
    "1. reps_num번 랩스 이미지들의 포인트 좌표 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c753370",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_coordinate = {}\n",
    "frame_num = 1 # 이미지(=프레임) 넘버링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d7051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for reps_num in range(1,11):\n",
    "    for i in range(1, 31):\n",
    "        dict_coordinate = {}\n",
    "        output, _ = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "                # (추가) 좌표 리스트를 딕셔너리에 추가\n",
    "        dict_coordinate[f'img_{reps_num}_{frame_num}'] = visualize_output(output)\n",
    "        df = pd.DataFrame(dict_coordinate)\n",
    "        df2 = df.T\n",
    "        # 4. df.to_csv()로 저장한다.\n",
    "        df2.to_csv(f'/Users/werther/dasol_squat_img/csv/no{reps_num}_images.csv')\n",
    "        print(f'{reps_num}')        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/werther/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525473998/work/aten/src/ATen/native/TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for reps_num in range(1,11):\n",
    "    for i in range(1, 31):\n",
    "        output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "        # (추가) 좌표 리스트를 딕셔너리에 추가\n",
    "        dict_coordinate[f'img_{reps_num}_{frame_num}'] = visualize_output(output)\n",
    "        print(f'{reps_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9906d9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "reps_num = 1 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5afa192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 2 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 3 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576923b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 4 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 5 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ee850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 6 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 7 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 8 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2310db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 9 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_coordinate = {}\n",
    "reps_num = 10 # 랩스 넘버링(초기값 1)\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    output, image = run_inference(f'/Users/werther/dasol_squat_img/dasol_squat_img/no{reps_num}/img_{reps_num}_{i}.jpg')\n",
    "    visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d7d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bb603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커널이 죽는 문제 발생으로 인해, 1랩스씩 돌려보기\n",
    "\n",
    "dict_coordinate = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c19784e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_coordinate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t4/vwr916y50fv3wcm0xlgfkyg00000gn/T/ipykernel_4840/3860198703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2. 추출한 좌표는 딕셔너리 dict_coordinate에 저장됨\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_coordinate' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. 추출한 좌표는 딕셔너리 dict_coordinate에 저장됨\n",
    "dict_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "854ee236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>img_1_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>373.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>380.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_5</th>\n",
       "      <td>432.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_6</th>\n",
       "      <td>431.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>...</td>\n",
       "      <td>387.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_7</th>\n",
       "      <td>430.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>...</td>\n",
       "      <td>395.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_8</th>\n",
       "      <td>430.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>401.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_9</th>\n",
       "      <td>430.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>404.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_10</th>\n",
       "      <td>429.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>...</td>\n",
       "      <td>405.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_11</th>\n",
       "      <td>429.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_12</th>\n",
       "      <td>430.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_13</th>\n",
       "      <td>430.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_14</th>\n",
       "      <td>428.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_15</th>\n",
       "      <td>426.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_16</th>\n",
       "      <td>424.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_17</th>\n",
       "      <td>421.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_18</th>\n",
       "      <td>420.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_19</th>\n",
       "      <td>418.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_20</th>\n",
       "      <td>417.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_21</th>\n",
       "      <td>415.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>401.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_22</th>\n",
       "      <td>415.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>395.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_23</th>\n",
       "      <td>415.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>388.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>382.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>381.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>377.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>378.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>376.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>374.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_1_30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4   ...     29     30     31     32  \\\n",
       "img_1_1     NaN    NaN    NaN    NaN    NaN  ...  374.0  498.0  509.0  357.0   \n",
       "img_1_2     NaN    NaN    NaN    NaN    NaN  ...  373.0  499.0  509.0  357.0   \n",
       "img_1_3     NaN    NaN    NaN    NaN    NaN  ...  371.0  500.0  510.0  356.0   \n",
       "img_1_4     NaN    NaN    NaN    NaN    NaN  ...  380.0  502.0  510.0  354.0   \n",
       "img_1_5   432.0   39.0  445.0   27.0  420.0  ...  380.0  506.0  513.0  352.0   \n",
       "img_1_6   431.0   67.0  444.0   55.0  418.0  ...  387.0  506.0  516.0  351.0   \n",
       "img_1_7   430.0  100.0  443.0   88.0  418.0  ...  395.0  504.0  518.0  352.0   \n",
       "img_1_8   430.0  133.0  443.0  120.0  417.0  ...  401.0  504.0  518.0  352.0   \n",
       "img_1_9   430.0  165.0  443.0  152.0  417.0  ...  404.0  505.0  520.0  353.0   \n",
       "img_1_10  429.0  190.0  442.0  177.0  415.0  ...  405.0  504.0  519.0  354.0   \n",
       "img_1_11  429.0  208.0  442.0  194.0  416.0  ...  403.0  503.0  519.0  354.0   \n",
       "img_1_12  430.0  217.0  442.0  204.0  416.0  ...  402.0  504.0  519.0  355.0   \n",
       "img_1_13  430.0  220.0  442.0  206.0  416.0  ...  402.0  504.0  519.0  356.0   \n",
       "img_1_14  428.0  220.0  441.0  206.0  414.0  ...  402.0  504.0  520.0  356.0   \n",
       "img_1_15  426.0  219.0  439.0  206.0  413.0  ...  402.0  504.0  519.0  356.0   \n",
       "img_1_16  424.0  218.0  436.0  205.0  410.0  ...  402.0  504.0  520.0  356.0   \n",
       "img_1_17  421.0  213.0  434.0  200.0  408.0  ...  403.0  505.0  518.0  354.0   \n",
       "img_1_18  420.0  201.0  432.0  187.0  406.0  ...  403.0  504.0  517.0  354.0   \n",
       "img_1_19  418.0  182.0  430.0  168.0  405.0  ...  403.0  505.0  517.0  354.0   \n",
       "img_1_20  417.0  157.0  429.0  144.0  404.0  ...  402.0  506.0  517.0  352.0   \n",
       "img_1_21  415.0  126.0  428.0  113.0  402.0  ...  401.0  505.0  516.0  353.0   \n",
       "img_1_22  415.0   91.0  427.0   78.0  402.0  ...  395.0  505.0  516.0  352.0   \n",
       "img_1_23  415.0   54.0  427.0   42.0  402.0  ...  388.0  506.0  515.0  351.0   \n",
       "img_1_24    NaN    NaN    NaN    NaN    NaN  ...  382.0  506.0  514.0  351.0   \n",
       "img_1_25    NaN    NaN    NaN    NaN    NaN  ...  381.0  505.0  510.0  352.0   \n",
       "img_1_26    NaN    NaN    NaN    NaN    NaN  ...  377.0  503.0  509.0  353.0   \n",
       "img_1_27    NaN    NaN    NaN    NaN    NaN  ...  378.0  500.0  509.0  356.0   \n",
       "img_1_28    NaN    NaN    NaN    NaN    NaN  ...  376.0  498.0  509.0  356.0   \n",
       "img_1_29    NaN    NaN    NaN    NaN    NaN  ...  374.0  498.0  508.0  356.0   \n",
       "img_1_30    NaN    NaN    NaN    NaN    NaN  ...  375.0  498.0  508.0  356.0   \n",
       "\n",
       "             33  \n",
       "img_1_1   507.0  \n",
       "img_1_2   506.0  \n",
       "img_1_3   506.0  \n",
       "img_1_4   507.0  \n",
       "img_1_5   507.0  \n",
       "img_1_6   509.0  \n",
       "img_1_7   509.0  \n",
       "img_1_8   509.0  \n",
       "img_1_9   511.0  \n",
       "img_1_10  511.0  \n",
       "img_1_11  513.0  \n",
       "img_1_12  514.0  \n",
       "img_1_13  514.0  \n",
       "img_1_14  514.0  \n",
       "img_1_15  514.0  \n",
       "img_1_16  514.0  \n",
       "img_1_17  512.0  \n",
       "img_1_18  512.0  \n",
       "img_1_19  511.0  \n",
       "img_1_20  511.0  \n",
       "img_1_21  509.0  \n",
       "img_1_22  509.0  \n",
       "img_1_23  509.0  \n",
       "img_1_24  508.0  \n",
       "img_1_25  508.0  \n",
       "img_1_26  508.0  \n",
       "img_1_27  507.0  \n",
       "img_1_28  507.0  \n",
       "img_1_29  506.0  \n",
       "img_1_30  506.0  \n",
       "\n",
       "[30 rows x 34 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. dict_coordinate를 데이터프레임 df으로 만든다\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dict_coordinate)\n",
    "df2 = df.T\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b79aaa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25ebe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. df.to_csv()로 저장한다.\n",
    "df2.to_csv(f'C:/Users/Playdata/Desktop/playdata/python/project/dataset/csv/eunseong_squat_45_csv/no{reps_num}_images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891723e0",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
